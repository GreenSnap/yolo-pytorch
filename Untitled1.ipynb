{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.utils.datasets.ggimages import OpenImage\n",
    "from src.utils.datasets.transform import RandomHorizontalFlip, Resize, Compose, XyToCenter\n",
    "import torchvision.transforms as transforms\n",
    "from src.utils.display.images import imshow, result_show\n",
    "from torch.utils.data import DataLoader\n",
    "from src.utils.datasets.adapter import convert_data\n",
    "import numpy as np\n",
    "from src.network.yolo import Yolo\n",
    "from src.config import VOC_ANCHORS\n",
    "from src.utils.process_boxes import preprocess_true_boxes\n",
    "\n",
    "general_transform = Compose([\n",
    "    Resize((608, 608)),\n",
    "    XyToCenter()\n",
    "])\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.RandomChoice([\n",
    "                    transforms.ColorJitter(hue=.1, saturation=.1),\n",
    "                    transforms.RandomGrayscale(p=0.7),\n",
    "                ]),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [\n",
    "                                     0.229, 0.224, 0.225])\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "\n",
    "ds = OpenImage('/data/data', 'OpenImage', general_transform=general_transform, transform=transform)\n",
    "\n",
    "train_data_loader = DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=convert_data, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.network.base import DarkNet, DarknetBody, YoloBody\n",
    "\n",
    "model = Yolo(VOC_ANCHORS, ds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yolo(\n",
      "  (yolo_body): YoloBody(\n",
      "    (body_bottom): DarknetBodyBottom(\n",
      "      (first_layer): Conv2d(\n",
      "        (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(32, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (second_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (third_layer): Conv2d(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(64, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "        (relu): LeakyReLU(negative_slope=0.1)\n",
      "      )\n",
      "      (forth_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (fifth_layer): BottleneckBlock(\n",
      "        (first_layer): Conv2d(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "        (second_layer): Conv2d(\n",
      "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(64, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "        (third_layer): Conv2d(\n",
      "          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "      )\n",
      "      (sixth_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (seventh_layer): BottleneckBlock(\n",
      "        (first_layer): Conv2d(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "        (second_layer): Conv2d(\n",
      "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(128, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "        (third_layer): Conv2d(\n",
      "          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "      )\n",
      "      (eighth_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (nineth_layer): DoubleBottleneckBlock(\n",
      "        (first_layer): BottleneckBlock(\n",
      "          (first_layer): Conv2d(\n",
      "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "            (relu): LeakyReLU(negative_slope=0.1)\n",
      "          )\n",
      "          (second_layer): Conv2d(\n",
      "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(256, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "            (relu): LeakyReLU(negative_slope=0.1)\n",
      "          )\n",
      "          (third_layer): Conv2d(\n",
      "            (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "            (relu): LeakyReLU(negative_slope=0.1)\n",
      "          )\n",
      "        )\n",
      "        (second_layer): Conv2d(\n",
      "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(256, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "        (third_layer): Conv2d(\n",
      "          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (body_head): DarknetBodyHead(\n",
      "      (tenth_layer): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      (eleventh_layer): DoubleBottleneckBlock(\n",
      "        (first_layer): BottleneckBlock(\n",
      "          (first_layer): Conv2d(\n",
      "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "            (relu): LeakyReLU(negative_slope=0.1)\n",
      "          )\n",
      "          (second_layer): Conv2d(\n",
      "            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(512, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "            (relu): LeakyReLU(negative_slope=0.1)\n",
      "          )\n",
      "          (third_layer): Conv2d(\n",
      "            (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(1024, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "            (relu): LeakyReLU(negative_slope=0.1)\n",
      "          )\n",
      "        )\n",
      "        (second_layer): Conv2d(\n",
      "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(512, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "        (third_layer): Conv2d(\n",
      "          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1024, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "          (relu): LeakyReLU(negative_slope=0.1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (first_layer): Conv2d(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(1024, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "      (relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (second_layer): Conv2d(\n",
      "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(1024, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "      (relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (find_grain): Conv2d(\n",
      "      (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(64, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "      (relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (re_org): Reorg()\n",
      "    (after_concat): Conv2d(\n",
      "      (conv): Conv2d(1280, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn): BatchNorm2d(1024, eps=0.001, momentum=0, affine=True, track_running_stats=True)\n",
      "      (relu): LeakyReLU(negative_slope=0.1)\n",
      "    )\n",
      "    (last_layer): Conv2d(1024, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  )\n",
      "  (yolo_head): YoloHead()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = next(iter(train_data_loader))\n",
    "batch_tensor, im_info, batch_boxes, batch_boxes_index, img_names = data\n",
    "\n",
    "\n",
    "detectors_mask, matching_true_boxes = preprocess_true_boxes(batch_boxes, VOC_ANCHORS, (608, 608), len(ds.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 1, 19, 19)\n"
     ]
    }
   ],
   "source": [
    "print(detectors_mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(batch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([748, 4])\n",
      "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,\n",
      "         15,  16,  17,  18,  19,  20,  21,  22,  24,  25,  26,  27,  28,  29,\n",
      "         30,  31,  32,  33,  34,  37,  38,  39,  40,  41,  42,  43,  45,  46,\n",
      "         47,  48,  49,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,\n",
      "         61,  62,  63,  64,  65,  66,  67,  68,  70,  71,  72,  73,  74,  75,\n",
      "         76,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103, 104,\n",
      "        105, 106, 107, 108, 109, 110, 112, 113, 114, 116, 117, 118, 119, 120,\n",
      "        121, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135,\n",
      "        137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150,\n",
      "        151, 152, 153, 154, 156, 157, 159, 160, 161, 162, 163, 164, 165, 166,\n",
      "        167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180,\n",
      "        181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
      "        195, 196, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 238, 240,\n",
      "        241, 242, 243, 244, 245, 247, 248, 249, 250, 251, 252, 255, 256, 257,\n",
      "        258, 259, 260, 261, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275,\n",
      "        277, 278, 280, 281, 282, 284, 286, 287, 288, 289, 290, 291, 292, 294,\n",
      "        295, 297, 299, 300, 301, 302, 304, 305, 306, 307, 308, 309, 310, 312,\n",
      "        313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326,\n",
      "        327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 338, 339, 340, 341,\n",
      "        342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 355, 356,\n",
      "        357, 358, 359, 360, 361, 362, 363, 364, 366, 367, 368, 370, 371, 372,\n",
      "        373, 374, 375, 376, 377, 379, 380, 381, 382, 383, 384, 385, 386, 388,\n",
      "        389, 390, 391, 392, 394, 395, 397, 398, 400, 401, 402, 403, 404, 405,\n",
      "        406, 407, 408, 409, 410, 411, 412, 413, 414, 416, 417, 418, 419, 420,\n",
      "        421, 422, 423, 424, 425, 426, 427, 428, 429, 431, 432, 433, 434, 435,\n",
      "        436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449,\n",
      "        450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463,\n",
      "        464, 465, 466, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478,\n",
      "        479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492,\n",
      "        493, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
      "        508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 520, 521, 522,\n",
      "        524, 525, 526, 527, 528, 530, 532, 533, 534, 535, 536, 537, 538, 539,\n",
      "        540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 552, 553, 555,\n",
      "        556, 557, 558, 559, 560, 561, 562, 563, 565, 566, 567, 568, 569, 570,\n",
      "        571, 572, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 585, 586,\n",
      "        587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600,\n",
      "        601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614,\n",
      "        615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 629,\n",
      "        630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643,\n",
      "        644, 645, 646, 647, 648, 650, 651, 652, 653, 654, 655, 656, 657, 658,\n",
      "        659, 661, 662, 663, 664, 665, 666, 668, 669, 670, 671, 672, 674, 675,\n",
      "        676, 677, 679, 680, 681, 682, 683, 684, 685, 687, 688, 690, 691, 692,\n",
      "        693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706,\n",
      "        707, 708, 709, 711, 712, 713, 714, 715, 716, 717, 718, 720, 722, 724,\n",
      "        725, 727, 728, 729, 732, 733, 737, 738, 739, 741, 742, 743, 745, 746,\n",
      "        747])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    result = model.eval(output, (608, 608), score_threshold=0.2, iou_threshold=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  2., 34.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor([1,2,34])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
